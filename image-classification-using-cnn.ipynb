{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Image Classification Using CNN**","metadata":{}},{"cell_type":"markdown","source":"# üì• Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport os # accessing directory structure\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv1D, Dropout, Activation, Flatten, InputLayer\nimport seaborn as sns\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPool2D\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomFlip, RandomRotation\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomZoom, RandomContrast, RandomTranslation\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T09:48:22.145105Z","iopub.execute_input":"2022-04-21T09:48:22.145580Z","iopub.status.idle":"2022-04-21T09:48:28.911290Z","shell.execute_reply.started":"2022-04-21T09:48:22.145495Z","shell.execute_reply":"2022-04-21T09:48:28.910533Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# üóÉÔ∏è Load Dataset\n","metadata":{}},{"cell_type":"code","source":"train_data_dir = \"../input/chessman-image-dataset/Chessman-image-dataset/Chess\"\nos.listdir(train_data_dir)\nimage_size = (229,131)\n\ndataset = image_dataset_from_directory(\n    train_data_dir,\n    image_size=image_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:35.828390Z","iopub.execute_input":"2022-04-21T09:48:35.828992Z","iopub.status.idle":"2022-04-21T09:48:36.059516Z","shell.execute_reply.started":"2022-04-21T09:48:35.828955Z","shell.execute_reply":"2022-04-21T09:48:36.058659Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# üî• Visualization\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 25))\nclass_names = dataset.class_names\nfor images, labels in dataset.take(1):\n    for i in range(15):\n        plt.subplot(7, 5, i + 1)\n        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:42.486462Z","iopub.execute_input":"2022-04-21T09:48:42.486950Z","iopub.status.idle":"2022-04-21T09:48:45.276279Z","shell.execute_reply.started":"2022-04-21T09:48:42.486899Z","shell.execute_reply":"2022-04-21T09:48:45.275545Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# ‚úÇÔ∏è Train & Test Split\n","metadata":{}},{"cell_type":"code","source":"train_dataset = image_dataset_from_directory(\n    train_data_dir,\n    validation_split=0.1,\n    seed=8,\n    subset=\"training\",\n    label_mode=\"categorical\",\n    image_size=image_size\n)\n\nvalidation_dataset = image_dataset_from_directory(\n    train_data_dir,\n    validation_split=0.1,\n    seed=6,\n    subset=\"validation\",\n    label_mode=\"categorical\",\n    image_size=image_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:57.878161Z","iopub.execute_input":"2022-04-21T09:48:57.878729Z","iopub.status.idle":"2022-04-21T09:48:58.138707Z","shell.execute_reply.started":"2022-04-21T09:48:57.878658Z","shell.execute_reply":"2022-04-21T09:48:58.137952Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# üìö Train The Models\n","metadata":{}},{"cell_type":"code","source":"data_augmentation = Sequential([\n    RandomFlip(\"horizontal\"),\n    RandomRotation(1./16),\n    RandomZoom((-0.1,0.1)),\n    RandomContrast(0.2),  \n    RandomTranslation(0.1,0.1)\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:49:08.592440Z","iopub.execute_input":"2022-04-21T09:49:08.593063Z","iopub.status.idle":"2022-04-21T09:49:08.609558Z","shell.execute_reply.started":"2022-04-21T09:49:08.593020Z","shell.execute_reply":"2022-04-21T09:49:08.608961Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## ü¶æ CNN Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(InputLayer(input_shape=(229,131, 3)))\nmodel.add(data_augmentation)\nmodel.add(Rescaling(scale=1./255))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\n\nmodel.add(Dense(6, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:57:35.710719Z","iopub.execute_input":"2022-04-21T10:57:35.711001Z","iopub.status.idle":"2022-04-21T10:57:36.003423Z","shell.execute_reply.started":"2022-04-21T10:57:35.710971Z","shell.execute_reply":"2022-04-21T10:57:36.002672Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model1 = model.fit(\n    train_dataset, \n    validation_data=validation_dataset, \n    epochs=30,\n    verbose=1)\n\nmodel.save('model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:57:46.588037Z","iopub.execute_input":"2022-04-21T10:57:46.588299Z","iopub.status.idle":"2022-04-21T11:12:32.665622Z","shell.execute_reply.started":"2022-04-21T10:57:46.588271Z","shell.execute_reply":"2022-04-21T11:12:32.664990Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"plt.plot(model1.history['accuracy'])\nplt.plot(model1.history['val_accuracy'],'r')\nplt.title('Training and Test Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(model1.history['loss'])\nplt.plot(model1.history['val_loss'],'r')\nplt.title('Training and Test Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T11:15:00.955621Z","iopub.execute_input":"2022-04-21T11:15:00.956558Z","iopub.status.idle":"2022-04-21T11:15:01.345861Z","shell.execute_reply.started":"2022-04-21T11:15:00.956506Z","shell.execute_reply":"2022-04-21T11:15:01.344875Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## ü¶æ Pre-trained CNN Models\n\nSome of the usage patterns as follows:\n\n- **Classifier:** The pre-trained model is used directly to classify new images.\n- **Standalone Feature Extractor:** The pre-trained model, or some portion of the model, is used to pre-process images and extract relevant features.\n- **Integrated Feature Extractor:** The pre-trained model, or some portion of the model, is integrated into a new model, but layers of the pre-trained model are frozen during training.\n- **Weight Initialization:** The pre-trained model, or some portion of the model, is integrated into a new model, and the layers of the pre-trained model are trained in concert with the new model.","metadata":{}},{"cell_type":"markdown","source":"### Integrated Feature Extractor","metadata":{}},{"cell_type":"markdown","source":"#### ‚úîÔ∏è InceptionV3 Model","metadata":{}},{"cell_type":"code","source":"## Pre-trained CNN model\n\nfrom tensorflow.python.keras.applications.inception_v3 import InceptionV3 \n\nmodel_inception_v3 = InceptionV3(\n    weights='../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', # Load pre-trained weights\n    include_top=False,  # Do not include the classifier at the top.\n    input_shape=(229,131,3))\n\n# Freeze the model, mark loaded layers as not trainable\nfor layer in model_inception_v3.layers:\n    layer.trainable = False\n\nmodel = Sequential()  # Create new model on top\nmodel.add(data_augmentation)  # Apply data augmentation\n\n# Pre-trained InceptionV3 weights requires that input be scaled\n# from (0, 255) to a range of (-1., +1.)\n# outputs: `(inputs * scale)`\nmodel.add(Rescaling(scale=1./255))\nmodel.add(model_inception_v3)  # Add entire model\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))\n\n    \nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:57:42.107224Z","iopub.execute_input":"2022-04-21T12:57:42.107530Z","iopub.status.idle":"2022-04-21T12:57:45.283908Z","shell.execute_reply.started":"2022-04-21T12:57:42.107498Z","shell.execute_reply":"2022-04-21T12:57:45.283150Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#This adds the entire model as a layer itself, so it's treated as one entity:\nfor index, layer in enumerate(model.layers):\n    print(\"Layer: {}, Trainable: {}\".format(index, layer.trainable))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:57:52.250939Z","iopub.execute_input":"2022-04-21T12:57:52.251259Z","iopub.status.idle":"2022-04-21T12:57:52.256536Z","shell.execute_reply.started":"2022-04-21T12:57:52.251229Z","shell.execute_reply":"2022-04-21T12:57:52.255881Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model2 = model.fit(\n    train_dataset, \n    validation_data=validation_dataset, \n    epochs=30,\n    verbose=1)\n\nmodel.save('model2.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:57:54.272928Z","iopub.execute_input":"2022-04-21T12:57:54.273806Z","iopub.status.idle":"2022-04-21T13:07:31.322660Z","shell.execute_reply.started":"2022-04-21T12:57:54.273767Z","shell.execute_reply":"2022-04-21T13:07:31.321361Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"plt.plot(model2.history['accuracy'])\nplt.plot(model2.history['val_accuracy'],'r')\nplt.title('Training and Test Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(model2.history['loss'])\nplt.plot(model2.history['val_loss'],'r')\nplt.title('Training and Test Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:10:46.324057Z","iopub.execute_input":"2022-04-21T13:10:46.324364Z","iopub.status.idle":"2022-04-21T13:10:46.742452Z","shell.execute_reply.started":"2022-04-21T13:10:46.324331Z","shell.execute_reply":"2022-04-21T13:10:46.741568Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"#### ‚úîÔ∏è Xception Model","metadata":{}},{"cell_type":"code","source":"## Pre-trained CNN model 2 \nfrom tensorflow.keras.applications import Xception\nxception = Xception(weights='../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(229,131,3))\nxception.trainable = False\n\nmodel = Sequential()\nmodel.add(data_augmentation)\nmodel.add(Rescaling(scale=1./255))\nmodel.add(xception)\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:38:07.450196Z","iopub.execute_input":"2022-04-21T10:38:07.450505Z","iopub.status.idle":"2022-04-21T10:38:10.116495Z","shell.execute_reply.started":"2022-04-21T10:38:07.450476Z","shell.execute_reply":"2022-04-21T10:38:10.115836Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model3 = model.fit(\n    train_dataset, \n    validation_data=validation_dataset, \n    epochs=30,\n    verbose=1)\n\nmodel.save('model3.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:38:11.844839Z","iopub.execute_input":"2022-04-21T10:38:11.845861Z","iopub.status.idle":"2022-04-21T10:52:13.552367Z","shell.execute_reply.started":"2022-04-21T10:38:11.845797Z","shell.execute_reply":"2022-04-21T10:52:13.551762Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.plot(model3.history['accuracy'])\nplt.plot(model3.history['val_accuracy'],'r')\nplt.title('Training and Test Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(model3.history['loss'])\nplt.plot(model3.history['val_loss'],'r')\nplt.title('Training and Test Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:52:22.717698Z","iopub.execute_input":"2022-04-21T10:52:22.718126Z","iopub.status.idle":"2022-04-21T10:52:23.113032Z","shell.execute_reply.started":"2022-04-21T10:52:22.718096Z","shell.execute_reply":"2022-04-21T10:52:23.112218Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"You can see the lines for both training and testing accuracies and losses are pretty close to each other which means that the model is not overfitting.","metadata":{}},{"cell_type":"markdown","source":"#### ‚úîÔ∏è NASNetLarge Model","metadata":{}},{"cell_type":"code","source":"## Pre-trained CNN model 3 \n\nfrom keras.applications.nasnet import NASNetLarge\n\nmodel_nasnet_large = NASNetLarge(weights='../input/nasnetlarge/NASNet-large-no-top.h5', include_top=False, input_shape=(229,131,3))\nmodel_nasnet_large.trainable = False\n\nmodel = Sequential()\nmodel.add(data_augmentation)\nmodel.add(Rescaling(scale=1./255))\n\nmodel.add(model_nasnet_large)\nmodel.add(Flatten())\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:12:16.991804Z","iopub.execute_input":"2022-04-21T13:12:16.992124Z","iopub.status.idle":"2022-04-21T13:12:29.408080Z","shell.execute_reply.started":"2022-04-21T13:12:16.992085Z","shell.execute_reply":"2022-04-21T13:12:29.407319Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"model4 = model.fit(\n    train_dataset, \n    validation_data=validation_dataset, \n    epochs=30,\n    verbose=1)\n\nmodel.save('model4.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:12:46.259281Z","iopub.execute_input":"2022-04-21T13:12:46.259543Z","iopub.status.idle":"2022-04-21T13:52:01.406854Z","shell.execute_reply.started":"2022-04-21T13:12:46.259515Z","shell.execute_reply":"2022-04-21T13:52:01.406012Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"plt.plot(model4.history['accuracy'])\nplt.plot(model4.history['val_accuracy'],'r')\nplt.title('Training and Test Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(model4.history['loss'])\nplt.plot(model4.history['val_loss'],'r')\nplt.title('Training and Test Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T13:52:55.653547Z","iopub.execute_input":"2022-04-21T13:52:55.653938Z","iopub.status.idle":"2022-04-21T13:52:56.076821Z","shell.execute_reply.started":"2022-04-21T13:52:55.653898Z","shell.execute_reply":"2022-04-21T13:52:56.075953Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"# üìä Testing","metadata":{}},{"cell_type":"code","source":"# Modify 'test1.jpg' and 'test2.jpg' to the images you want to predict on\n\nfrom keras.models import load_model\nfrom keras.preprocessing import image\n\n# dimensions of our images\nimg_width, img_height = 229, 131\n\n# load the model we saved\nbest_model = load_model('model3.h5')\nbest_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['accuracy'])\n\n# predicting images\nimg = image.load_img('../input/test-image/test1.jpg', target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = best_model.predict(images)\nprint(classes)\n\nplt.imshow(img)\nplt.title('%98 Knight', color=\"b\",fontweight='bold',size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:27:52.087230Z","iopub.execute_input":"2022-04-21T14:27:52.087537Z","iopub.status.idle":"2022-04-21T14:27:55.307640Z","shell.execute_reply.started":"2022-04-21T14:27:52.087501Z","shell.execute_reply":"2022-04-21T14:27:55.306404Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# predicting images\nimg = image.load_img('../input/test-image/test2.jpg', target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = best_model.predict(images)\nprint(classes)\n\nplt.imshow(img)\nplt.title('%99 Rook', color=\"b\",fontweight='bold',size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:27:44.560867Z","iopub.execute_input":"2022-04-21T14:27:44.561142Z","iopub.status.idle":"2022-04-21T14:27:44.861299Z","shell.execute_reply.started":"2022-04-21T14:27:44.561113Z","shell.execute_reply":"2022-04-21T14:27:44.860384Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# predicting images\nimg = image.load_img('../input/test-image/test3.jpg', target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = best_model.predict(images)\nprint(classes)\n\nplt.imshow(img)\nplt.title('%0.1 (Queen)', color=\"r\",fontweight='bold',size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:32:44.746820Z","iopub.execute_input":"2022-04-21T14:32:44.747644Z","iopub.status.idle":"2022-04-21T14:32:45.057438Z","shell.execute_reply.started":"2022-04-21T14:32:44.747593Z","shell.execute_reply":"2022-04-21T14:32:45.056765Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# predicting images\nimg = image.load_img('../input/test-image/test4.jpg', target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = best_model.predict(images)\nprint(classes)\n\nplt.imshow(img)\nplt.title('%35 Queen', color=\"r\",fontweight='bold',size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:31:26.799198Z","iopub.execute_input":"2022-04-21T14:31:26.799487Z","iopub.status.idle":"2022-04-21T14:31:27.102231Z","shell.execute_reply.started":"2022-04-21T14:31:26.799458Z","shell.execute_reply":"2022-04-21T14:31:27.101568Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# predicting images\nimg = image.load_img('../input/test-image/test5.png', target_size=(img_width, img_height))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = best_model.predict(images)\nprint(classes)\n\nplt.imshow(img)\nplt.title('%99 Bishop)', color=\"b\",fontweight='bold',size=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T14:27:34.359105Z","iopub.execute_input":"2022-04-21T14:27:34.359388Z","iopub.status.idle":"2022-04-21T14:27:34.656742Z","shell.execute_reply.started":"2022-04-21T14:27:34.359358Z","shell.execute_reply":"2022-04-21T14:27:34.656059Z"},"trusted":true},"execution_count":102,"outputs":[]}]}